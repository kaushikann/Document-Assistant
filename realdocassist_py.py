# -*- coding: utf-8 -*-
"""RealDocAssist.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DFqH0zqcrt0uy9ovk7OfmQFdDgsLy8nt
"""

#LLM Model Import
from langchain_openai import ChatOpenAI
gpt4omini=ChatOpenAI(model="gpt-4o-mini", temperature=0.5)

#Streamlit import
import streamlit as st

#secrets
import os
os.environ["OPENAI_API_KEY"]=st.secrets["OPENAI_API_KEY"]
os.environ["PINECONE_API_KEY"]=st.secrets["PINECONE_API_KEY"]

#PDF Reader import
from PyPDF2 import PdfReader

#Text-splitter import
from langchain_text_splitters import RecursiveCharacterTextSplitter
text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

#Embeddings import
from langchain_openai import OpenAIEmbeddings
embeddings=OpenAIEmbeddings(model="text-embedding-3-small")

#Vector DB import
from langchain_pinecone import PineconeVectorStore

#Prompt Template import
from langchain_core.prompts import PromptTemplate
finalquestion_template="You need to answer the question - {question}, given the context - {context}"
finalquestion_prompt=PromptTemplate(template=finalquestion_template, input_variables=["question", "context"])

#System Message import
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

#Retrieval QA import
from langchain.chains import RetrievalQA

#LLm Chain import
from langchain.chains import LLMChain
docchain= finalquestion_prompt | gpt4omini

#Extracting document function
def process_file(uploaded_file):
    text=""
    loader=PdfReader(uploaded_file)
    for page in loader.pages:
        text+=page.extract_text()
    return text

#Splitting function
def pdf_splitter(text):
    chunks=text_splitter.split_text(text)
    return chunks

#vector function
def vectordb(chunks):
    index="chapter"
    vectorstore=PineconeVectorStore.from_documents(chunks, embeddings,index_name=index )
    return vectorstore

#Main
st.header("Document Assistant")
st.subheader("Upload a PDF document and ask questions about it")
uploaded_file=st.file_uploader("Upload", type="pdf")
if st.button("Process"):
    st.write("Processing...")
    documents=process_file(uploaded_file)
    chunks=pdf_splitter(documents)
    vectorstore=vectordb(chunks)
    st.write("Done!")
    question=st.text_area("Ask a question about the document",label_visibility="visible")
    qa=RetrievalQA.from_chain_type(llm=gpt4omini, chain_type="stuff", retriever=vectorstore.as_retriever())
    context=qa.invoke(question)
    finalresponse= docchain.invoke({"question":question, "context":context})
    st.write(finalresponse)
